{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a367d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02124f3a",
   "metadata": {},
   "source": [
    "- a * b 矩阵按位相乘，要求：矩阵shape相同\n",
    "- torch.matmul(a, b)  == a @ b(完全等价) 矩阵相乘，支持broadcast；要求：a的列数等于b的行数\n",
    "    - torch.dot():1d,不支持broadcast  （子集）\n",
    "    - torch.mm():2d,不支持broadcast 要求：a的列数等于b的行数\n",
    "    - torch.bmm():3d batch,不支持broadcast 要求：第一维的batch必须相同，按第一维展开后的shape满足：a的列数等于b的行数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c9c848",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1936d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.tensor([2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2916174c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46058051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e5c3c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8f3eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb55cdc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b #[2*2,3*1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7af7464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = torch.randn(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "556fccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat2 = torch.randn(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "026aa1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3141,  2.1072,  0.0137],\n",
       "        [ 0.7974, -0.5378, -0.0806],\n",
       "        [ 0.9115, -0.0333, -1.6266]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce5933b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2927,  0.3170,  0.6755],\n",
       "        [ 1.0018, -0.9842, -0.2831]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bb94fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9604, -0.8097, -1.1283],\n",
       "        [-1.3575,  2.6497,  0.5536]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(mat1,mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f962c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9604, -0.8097, -1.1283],\n",
       "        [-1.3575,  2.6497,  0.5536]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(mat1,mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb445094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9604, -0.8097, -1.1283],\n",
       "        [-1.3575,  2.6497,  0.5536]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 @ mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e0055ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5799402",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat3 = torch.randn(2,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8616f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5496,  0.8799,  2.1138, -0.7615, -0.4350],\n",
       "         [ 1.2712,  1.2324, -1.6242,  1.7839,  0.9475],\n",
       "         [ 1.4447,  0.4004, -1.3616,  1.9769, -0.0675]],\n",
       "\n",
       "        [[ 4.0265,  1.4014,  1.9333,  1.3998, -4.1329],\n",
       "         [ 0.5957,  0.5290, -0.6335,  1.0413, -0.3238],\n",
       "         [ 3.2690,  2.5884,  0.5076,  0.7277, -2.0497]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(input,mat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ec39cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5496,  0.8799,  2.1138, -0.7615, -0.4350],\n",
       "         [ 1.2712,  1.2324, -1.6242,  1.7839,  0.9475],\n",
       "         [ 1.4447,  0.4004, -1.3616,  1.9769, -0.0675]],\n",
       "\n",
       "        [[ 4.0265,  1.4014,  1.9333,  1.3998, -4.1329],\n",
       "         [ 0.5957,  0.5290, -0.6335,  1.0413, -0.3238],\n",
       "         [ 3.2690,  2.5884,  0.5076,  0.7277, -2.0497]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(input,mat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5eb9aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5496,  0.8799,  2.1138, -0.7615, -0.4350],\n",
       "         [ 1.2712,  1.2324, -1.6242,  1.7839,  0.9475],\n",
       "         [ 1.4447,  0.4004, -1.3616,  1.9769, -0.0675]],\n",
       "\n",
       "        [[ 4.0265,  1.4014,  1.9333,  1.3998, -4.1329],\n",
       "         [ 0.5957,  0.5290, -0.6335,  1.0413, -0.3238],\n",
       "         [ 3.2690,  2.5884,  0.5076,  0.7277, -2.0497]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input @ mat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6308052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5496,  0.8799,  2.1138, -0.7615, -0.4350],\n",
      "        [ 1.2712,  1.2324, -1.6242,  1.7839,  0.9475],\n",
      "        [ 1.4447,  0.4004, -1.3616,  1.9769, -0.0675]])\n",
      "tensor([[ 4.0265,  1.4014,  1.9333,  1.3998, -4.1329],\n",
      "        [ 0.5957,  0.5290, -0.6335,  1.0413, -0.3238],\n",
      "        [ 3.2690,  2.5884,  0.5076,  0.7277, -2.0497]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(torch.mm(input[i,:,:],mat3[i,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80c1cd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(3, 4)\n",
    "x = torch.randn(4) \n",
    "y = A @ x  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ea8c760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8465,  1.7365, -0.1117, -0.8887],\n",
       "        [ 0.1683, -0.3218,  0.9915, -0.8987],\n",
       "        [-0.6140,  0.4684,  0.6307, -0.0406]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d73e79a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.22819439"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8465*(-0.7986)+1.7365*(-1.3096)+(-0.1117)*1.3174+(-0.8887)*0.1473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdde929b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7986, -1.3096,  1.3174,  0.1473])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e0fa7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.2281,  1.4609,  0.7018])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e17ac4",
   "metadata": {},
   "source": [
    "这里的 broadcast（广播） 指的是：当参与运算的张量在某些维度上大小不一致时，PyTorch 会按规则**把某些维度为 1 的那一方“虚拟扩展（expand）”**到匹配的大小，从而让运算能一次性在“批维/前置维”上并行进行；这个扩展通常不是真拷贝数据，而是视图层面的“重复使用”。\n",
    "1) torch.matmul(a, b) / a @ b 的广播：广播的是“批维（前置维）”\n",
    "对于高维（... 表示若干前置维）：\n",
    "\n",
    "a 形状：(..., m, k)\n",
    "b 形状：(..., k, n)\n",
    "输出：(..., m, n)\n",
    "其中 ... 这些前置维会按 broadcasting 规则对齐；最后两维 (m,k) 和 (k,n) 仍必须满足矩阵乘法条件：k 相等。\n",
    "\n",
    "例 1：b 没有 batch 维，自动广播到每个 batch\n",
    "python\n",
    "a = torch.randn(10, 3, 4)  # (batch=10, m=3, k=4)\n",
    "b = torch.randn(4, 5)      # (k=4, n=5)\n",
    "\n",
    "y = a @ b                  # -> (10, 3, 5)\n",
    "理解：把 b 视作 (1, 4, 5)，广播成 (10, 4, 5) 后，对 10 个 batch 分别做矩阵乘法。\n",
    "\n",
    "例 2：双方都有 batch 维，但某一方 batch=1，被广播\n",
    "python\n",
    "a = torch.randn(2, 1, 3, 4)  # (...=2,1, m=3, k=4)\n",
    "b = torch.randn(1, 7, 4, 5)  # (...=1,7, k=4, n=5)\n",
    "\n",
    "y = a @ b                    # -> (2, 7, 3, 5)\n",
    "这里前置维分别是 (2,1) 和 (1,7)，广播结果是 (2,7)。\n",
    "\n",
    "2) 为什么 mm / bmm 说“不支持 broadcast”\n",
    "torch.mm(a, b)：只接受 2D，不存在“批维”可广播\n",
    "python\n",
    "a = torch.randn(10, 3, 4)\n",
    "b = torch.randn(4, 5)\n",
    "torch.mm(a, b)  # 报错：a 不是 2D\n",
    "torch.bmm(a, b)：只接受 3D，且 batch 维必须完全相同\n",
    "python\n",
    "a = torch.randn(10, 3, 4)  # (batch=10, m=3, k=4)\n",
    "b = torch.randn(1, 4, 5)   # (batch=1,  k=4, n=5)\n",
    "\n",
    "torch.bmm(a, b)            # 报错：batch 维 10 != 1（不会帮你广播）\n",
    "但同样的形状用 matmul 可以：\n",
    "\n",
    "python\n",
    "a @ b  # b 会被广播到 batch=10，结果 (10, 3, 5)\n",
    "3) 一句话总结\n",
    "matmul/@：会对**前置维（batch 维）**做广播；最后两维仍需满足矩阵乘法的 \n",
    "k\n",
    "k 对齐。\n",
    "mm：2D 专用，无广播。\n",
    "bmm：3D batch 专用，但 batch 维必须相同，无广播。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e6ba43",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
